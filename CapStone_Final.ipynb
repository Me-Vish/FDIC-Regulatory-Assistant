{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üìò Project Overview: FDIC Regulatory Assistant\n",
        "\n",
        "## üîç The Problem\n",
        "Banks must process a large number of loan applications while ensuring strict\n",
        "adherence to complex federal regulations. Manually reviewing each loan against\n",
        "the FDIC Risk Management Supervision (RMS) Manual is time-consuming and prone\n",
        "to human error.\n",
        "\n",
        "---\n",
        "\n",
        "## üí° The Solution\n",
        "This project builds an AI-powered regulatory assistant that:\n",
        "- Reads loan documents\n",
        "- Extracts key loan information\n",
        "- Searches only the **FDIC RMS Manual ‚Äì Section 3.2 (Loans)**\n",
        "- Provides document-grounded regulatory risk considerations\n",
        "- Does **not** approve, reject, or determine compliance for loans\n",
        "\n",
        "The system produces **audit-ready, consistent, and regulator-aligned outputs**\n",
        "suitable for senior banking officials.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "XvhhJ1pL_Lfz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚öôÔ∏è Step-by-Step Notebook Explanation"
      ],
      "metadata": {
        "id": "4vvJ8RaPEZvS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üõ†Ô∏è Step 1: Environment & Tool Setup\n",
        "This cell prepares the workspace so the project runs smoothly.\n",
        "\n",
        "- Installs required libraries for AI, PDF processing, OCR, and the web interface\n",
        "- Applies system patches to avoid runtime issues in Google Colab"
      ],
      "metadata": {
        "id": "AKLEhvoj_Qht"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "xoO1_FLkN8DD",
        "outputId": "ccf07c2a-3a68-461c-bcd2-ba3d19baaf6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (2.12.0)\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.12/dist-packages (6.6.0)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.50.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.12/dist-packages (0.3.13)\n",
            "Requirement already satisfied: pdf2image in /usr/local/lib/python3.12/dist-packages (1.17.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.12/dist-packages (1.6.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.12.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.12.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.12.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.2.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.123.10)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (1.0.0)\n",
            "Requirement already satisfied: gradio-client==1.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.14.0)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.36.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.3)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.3)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.14.9)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.7)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.50.0)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.20.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.14.0->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=13.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.14.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastapi<1.0,>=0.115.2->gradio) (0.0.4)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (3.20.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (2.32.4)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.3.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (2.5.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.1.1-2.1build1).\n",
            "poppler-utils is already the newest version (22.02.0-2ubuntu0.12).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 1 not upgraded.\n",
            "Requirement already satisfied: uvicorn==0.25.0 in /usr/local/lib/python3.12/dist-packages (0.25.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.12/dist-packages (from uvicorn==0.25.0) (8.3.1)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.12/dist-packages (from uvicorn==0.25.0) (0.16.0)\n",
            "‚úÖ Environment patched with compatible versions.\n"
          ]
        }
      ],
      "source": [
        "!pip install openai pypdf gradio numpy pytesseract pdf2image pillow nest_asyncio\n",
        "!apt-get install poppler-utils tesseract-ocr\n",
        "!pip install \"uvicorn==0.25.0\"\n",
        "\n",
        "# Apply the Asyncio Patch\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "print(\"‚úÖ Environment patched with compatible versions.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üì¶ Step 2: Core Library Imports\n",
        "This cell loads all Python libraries needed for the project.\n",
        "\n",
        "- Data and AI libraries for numerical processing and language model interaction\n",
        "- File-handling tools for reading PDFs and images"
      ],
      "metadata": {
        "id": "H1-_4e7c_VcK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6pE-P_DTN-3_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pickle\n",
        "import json\n",
        "import numpy as np\n",
        "import gradio as gr\n",
        "import pytesseract\n",
        "from PIL import Image\n",
        "from pdf2image import convert_from_path\n",
        "from pypdf import PdfReader\n",
        "from openai import OpenAI\n",
        "from google.colab import files\n",
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîê Step 3: Secure Connection & Storage\n",
        "This cell connects the project to external services securely.\n",
        "\n",
        "- Mounts Google Drive to store processed data and avoid repeated computation"
      ],
      "metadata": {
        "id": "cYlMBjVjE1DA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- FIX: MOUNT GOOGLE DRIVE ---\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "print(\"‚úÖ Google Drive Mounted!\")"
      ],
      "metadata": {
        "id": "DbALQ1J3E0BX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c8e2243-f669-4b30-d342-6245b345cceb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "‚úÖ Google Drive Mounted!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîë Step 4: Initialize OpenAI Client\n",
        "\n",
        "Initializes the OpenAI client using credentials stored securely\n",
        "in Google Colab's user data (secrets).\n",
        "\n",
        "Why this is important:\n",
        "- Keeps API keys out of the code\n",
        "- Supports clean, secure authentication\n",
        "- Allows switching base URLs if required\n"
      ],
      "metadata": {
        "id": "AGpy8DxJ_Yse"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PwGvmrkFOA27",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da324781-6ccf-4eff-da48-822af84130cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Client initialized with custom Base URL.\n"
          ]
        }
      ],
      "source": [
        "# Setup Client using Google Colab User Data (Secrets)\n",
        "api_key = userdata.get('API_KEY')\n",
        "base_url = userdata.get('BASE_URL')\n",
        "\n",
        "client = OpenAI(\n",
        "    api_key=api_key,\n",
        "    base_url=base_url\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Client initialized with custom Base URL.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìÑ Step 5: Manual Upload & Verification\n",
        "This cell ensures the regulatory source document is available.\n",
        "\n",
        "- Checks for the presence of `section3-2.pdf`\n",
        "- Prompts the user to upload the document if it is missing\n",
        "\n",
        "This enforces a **single source of truth** for all responses."
      ],
      "metadata": {
        "id": "oyCt3Cuf_bdP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hv8R5s20OEFM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04ac03ef-4701-458d-dd70-97b2e1bb479b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ '/content/drive/My Drive/section3-2.pdf' found. Skipping upload.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "# Check if file exists, if not, prompt upload\n",
        "pdf_filename = \"/content/drive/My Drive/section3-2.pdf\" # <-- MATCH THIS NAME\n",
        "\n",
        "if not os.path.exists(pdf_filename):\n",
        "    print(f\"Please upload the Regulatory Document: '{pdf_filename}'\")\n",
        "    uploaded = files.upload()\n",
        "    # Rename the uploaded file to match expected name\n",
        "    for filename in uploaded.keys():\n",
        "        os.rename(filename, pdf_filename)\n",
        "        print(f\"File saved as {pdf_filename}\")\n",
        "else:\n",
        "    print(f\"‚úÖ '{pdf_filename}' found. Skipping upload.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üß† Step 6: Smart Search Memory (Embedding Cache)\n",
        "This cell builds a fast semantic search system for the FDIC manual.\n",
        "\n",
        "- Splits the PDF into small overlapping text chunks\n",
        "- Converts text chunks into embeddings for semantic search\n",
        "- Stores the embeddings so they can be reused across sessions\n",
        "\n",
        "This improves performance and reduces API cost."
      ],
      "metadata": {
        "id": "zAcrb_wp_eFJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gm4LUsDLOIn4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db91c43e-ca06-4d85-cb16-74b232af80c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ö†Ô∏è Cache not found in Drive. Generating embeddings...\n",
            "Reading PDF: /content/drive/My Drive/section3-2.pdf...\n",
            "Processing batch 0...\n",
            "Processing batch 50...\n",
            "Processing batch 100...\n",
            "Processing batch 150...\n",
            "Processing batch 200...\n",
            "Processing batch 250...\n",
            "Processing batch 300...\n",
            "Processing batch 350...\n",
            "Processing batch 400...\n",
            "Processing batch 450...\n",
            "Processing batch 500...\n",
            "‚úÖ Saved to Google Drive: /content/drive/My Drive/fdic_embeddings_cache.pkl\n"
          ]
        }
      ],
      "source": [
        "# --- FIX: SAVE TO DRIVE INSTEAD OF LOCAL DISK ---\n",
        "# This path is inside your actual Google Drive\n",
        "EMBEDDING_FILE = \"/content/drive/My Drive/fdic_embeddings_cache.pkl\"\n",
        "EMBEDDING_MODEL = \"text-embedding-3-small\"\n",
        "\n",
        "def load_and_chunk_pdf(pdf_path):\n",
        "    print(f\"Reading PDF: {pdf_path}...\")\n",
        "    reader = PdfReader(pdf_path)\n",
        "    text = \"\"\n",
        "    for page in reader.pages:\n",
        "        t = page.extract_text()\n",
        "        if t: text += t + \"\\n\"\n",
        "    return [text[i:i+1000] for i in range(0, len(text), 900)]\n",
        "\n",
        "def get_embedding_batch(texts):\n",
        "    res = client.embeddings.create(input=texts, model=EMBEDDING_MODEL)\n",
        "    return [d.embedding for d in res.data]\n",
        "\n",
        "# Check Google Drive for the file\n",
        "if os.path.exists(EMBEDDING_FILE):\n",
        "    print(f\"‚úÖ Cache found in Google Drive! Loading...\")\n",
        "    with open(EMBEDDING_FILE, 'rb') as f:\n",
        "        data = pickle.load(f)\n",
        "        chunks = data['chunks']\n",
        "        chunk_embeddings_np = data['embeddings']\n",
        "    print(\"Knowledge base loaded without spending API credits.\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Cache not found in Drive. Generating embeddings...\")\n",
        "\n",
        "    # --- FIX: CHECK FOR THE CORRECT FILENAME FROM CELL 4 ---\n",
        "    if os.path.exists(pdf_filename):  # Uses \"section3-2.pdf\" variable from Cell 4\n",
        "        chunks = load_and_chunk_pdf(pdf_filename)\n",
        "        chunk_embeddings = []\n",
        "\n",
        "        batch_size = 50\n",
        "        for i in range(0, len(chunks), batch_size):\n",
        "            print(f\"Processing batch {i}...\")\n",
        "            batch_embeddings = get_embedding_batch(chunks[i:i+batch_size])\n",
        "            chunk_embeddings.extend(batch_embeddings)\n",
        "\n",
        "        chunk_embeddings_np = np.array(chunk_embeddings)\n",
        "\n",
        "        # Save to Google Drive\n",
        "        with open(EMBEDDING_FILE, 'wb') as f:\n",
        "            pickle.dump({'chunks': chunks, 'embeddings': chunk_embeddings_np}, f)\n",
        "        print(f\"‚úÖ Saved to Google Drive: {EMBEDDING_FILE}\")\n",
        "    else:\n",
        "        print(f\"‚ùå Error: {pdf_filename} missing. Please run the Upload cell (Cell 4) again.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üñºÔ∏è Step 7: Extract Raw Text from Uploaded Loan Documents\n",
        "\n",
        "Handles user-uploaded loan documents.\n",
        "\n",
        "Supported formats:\n",
        "- Image files (PNG, JPG)\n",
        "- PDF files (scanned or digital)\n",
        "\n",
        "How it works:\n",
        "- Images ‚Üí OCR using Tesseract\n",
        "- PDFs ‚Üí Converted to images, then OCR applied\n",
        "\n",
        "The output is **raw, unstructured text** from the loan application.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dgPc1_rw_jYf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1L53sGFsOK3P"
      },
      "outputs": [],
      "source": [
        "def extract_text_from_file(filepath):\n",
        "    \"\"\"OCR Logic: Convert Image/PDF to Raw Text\"\"\"\n",
        "    text = \"\"\n",
        "    try:\n",
        "        if filepath.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "            image = Image.open(filepath)\n",
        "            text = pytesseract.image_to_string(image)\n",
        "        elif filepath.lower().endswith('.pdf'):\n",
        "            images = convert_from_path(filepath)\n",
        "            for img in images:\n",
        "                text += pytesseract.image_to_string(img) + \"\\n\"\n",
        "    except Exception as e:\n",
        "        return f\"Error reading file: {str(e)}\"\n",
        "    return text"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üßæ Step 8: Convert Raw Loan Text into Structured Data\n",
        "\n",
        "This cell uses the language model to extract key loan fields\n",
        "from the raw OCR text and convert them into clean JSON.\n",
        "\n",
        "Extracted fields include:\n",
        "- Borrower Name\n",
        "- Loan Amount\n",
        "- Interest Rate\n",
        "- Purpose\n",
        "- Address\n",
        "- Income\n",
        "- Credit Score (if available)"
      ],
      "metadata": {
        "id": "rrzXBJ_JF1O-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def structure_loan_data(raw_text):\n",
        "    \"\"\"LLM Logic: Convert Raw Text to Clean JSON\"\"\"\n",
        "    system_prompt = \"\"\"\n",
        "    You are a Data Extraction Specialist.\n",
        "    Task: Extract key loan application details from the OCR text.\n",
        "    Output: Return ONLY a valid JSON object. No markdown, no commentary.\n",
        "    Fields: Borrower Name, Loan Amount, Interest Rate, Purpose, Address, Income, Credit Score (if available).\n",
        "    \"\"\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4.1-nano\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": raw_text}\n",
        "        ],\n",
        "        temperature=0,\n",
        "        top_p=1,\n",
        "        frequency_penalty=0,\n",
        "        presence_penalty=0\n",
        "    )\n",
        "\n",
        "    # Clean up response to ensure valid JSON\n",
        "    content = response.choices[0].message.content\n",
        "    content = content.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
        "    return content"
      ],
      "metadata": {
        "id": "BNF_Qw9xFz6C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîç Step 9: Retrieve Relevant Regulatory Context\n",
        "\n",
        "This cell performs **semantic retrieval** using embeddings.\n",
        "\n",
        "Process:\n",
        "1. The user query is converted into an embedding\n",
        "2. It is compared against stored document embeddings\n",
        "3. The most relevant regulatory chunks are selected\n",
        "\n",
        "This ensures:\n",
        "- Only relevant portions of Section 3.2 are used\n",
        "- The language model never sees the full document\n",
        "- Hallucination risk is minimized\n"
      ],
      "metadata": {
        "id": "kc9N9prkGZiC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "edBP5UyXOMmu"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import asyncio\n",
        "\n",
        "# --- 1. RETRIEVAL LOGIC (Fixed for Broader Context) ---\n",
        "def find_relevant_context(query):\n",
        "    # Retrieve top 10 chunks to ensure we catch the \"General Policy\" intro sections\n",
        "    q_vec = client.embeddings.create(input=[query], model=EMBEDDING_MODEL).data[0].embedding\n",
        "    sims = np.dot(chunk_embeddings_np, np.array(q_vec))\n",
        "\n",
        "    # CHANGE 1: Increased from 5 to 10 to catch broad regulatory pillars\n",
        "    top_idxs = np.argsort(sims)[-10:][::-1]\n",
        "\n",
        "    return \"\\n\\n---------------------\\n\".join([chunks[i] for i in top_idxs])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üß† Step 10: Generate Regulatory Answer Using Prompt Engineering\n",
        "\n",
        "This is the core reasoning step.\n",
        "\n",
        "The system prompt:\n",
        "- Defines the role (senior bank manager)\n",
        "- Restricts answers to FDIC Section 3.2\n",
        "- Prohibits approval, rejection, or compliance decisions\n",
        "- Enforces refusal if information is missing\n",
        "- Prevents showing internal reasoning\n",
        "\n",
        "The model receives:\n",
        "- Retrieved regulatory context\n",
        "- Structured loan data\n",
        "- The user‚Äôs regulatory question\n",
        "\n",
        "The output is a **formal, document-grounded regulatory response**.\n"
      ],
      "metadata": {
        "id": "pGwCquK1Ghl1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import asyncio\n",
        "\n",
        "\n",
        "# --- PIPELINE LOGIC ---\n",
        "async def process_pipeline(file_obj, user_query):\n",
        "    structured_json = \"{}\"\n",
        "\n",
        "    # A. HANDLE FILE UPLOAD\n",
        "    if file_obj is not None:\n",
        "        print(f\"Processing file: {file_obj.name}\")\n",
        "        raw_text = await asyncio.to_thread(extract_text_from_file, file_obj.name)\n",
        "        print(\"Structuring data (LLM)...\")\n",
        "        structured_json = await asyncio.to_thread(structure_loan_data, raw_text)\n",
        "    else:\n",
        "        print(\"No file uploaded. Skipping OCR.\")\n",
        "        structured_json = json.dumps({\"Info\": \"No loan provided. Answering based on regulations only.\"})\n",
        "\n",
        "    # B. RETRIEVE CONTEXT\n",
        "    print(\"Retrieving context...\")\n",
        "    context = await asyncio.to_thread(find_relevant_context, user_query)\n",
        "\n",
        "    # C. GENERATE ANSWER\n",
        "    system_prompt = f\"\"\"\n",
        "Role:\n",
        "You are a senior bank manager responsible for reviewing loan-related matters, acting in the role of a strict FDIC regulatory compliance officer.\n",
        "\n",
        "Regulatory Context (FDIC Risk Management Supervision Manual ‚Äì Section 3.2):\n",
        "{context}\n",
        "\n",
        "Loan Data:\n",
        "{structured_json}\n",
        "\n",
        "Instructions:\n",
        "\n",
        "Use only the document titled ‚ÄúFDIC Risk Management Supervision Manual ‚Äì Section 3.2 (Loans)‚Äù as your source.\n",
        "\n",
        "Carefully review the entire provided text before answering, and identify relevant requirements even if the wording in the question differs from the wording used in the document.\n",
        "\n",
        "Answer whenever Section 3.2 addresses the regulatory requirement or expectation in substance, including cases where the answer must be derived by combining guidance from multiple parts of the text.\n",
        "\n",
        "Use the same terminology as the document. Do not add assumptions, interpretations, or outside knowledge.\n",
        "\n",
        "Output response:\n",
        "\n",
        "You may think internally, but do not show your reasoning.\n",
        "\n",
        "Reply with ‚ÄúThe provided document does not contain information to answer this question.‚Äù only if Section 3.2 does not address the subject in any form.\n",
        "\n",
        "Provide only the final answer.\n",
        "\n",
        "The final answer must be consise and precise to the point like a summarized version.\n",
        "\"\"\"\n",
        "\n",
        "    response = await asyncio.to_thread(\n",
        "        client.chat.completions.create,\n",
        "        model=\"gpt-4.1-nano\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": user_query}\n",
        "        ],\n",
        "        temperature=0.3 # Slightly increased to allow synthesis of multiple chunks\n",
        "    )\n",
        "\n",
        "    return structured_json, response.choices[0].message.content, context"
      ],
      "metadata": {
        "id": "aFjVvnG7GgSZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üñ•Ô∏è Step 11: Interactive Chat Interface\n",
        "\n",
        "This cell builds a Gradio-based UI that allows users to:\n",
        "- Upload a loan document (optional)\n",
        "- Ask a regulatory question\n",
        "- View structured loan data\n",
        "- View the regulatory answer\n",
        "- View retrieved regulatory context for verification\n",
        "\n",
        "This improves transparency and auditability.\n",
        "\n"
      ],
      "metadata": {
        "id": "uS9keyTNDZrz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "import gradio as gr\n",
        "\n",
        "# Apply patch immediately before launch\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# --- GRADIO INTERFACE SETUP ---\n",
        "with gr.Blocks(title=\"Loan Validator\") as demo:\n",
        "    gr.Markdown(\"# üè¶ FDIC Loan Validator\")\n",
        "    gr.Markdown(\"Upload a loan application image (optional) and ask a regulatory question.\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            file_input = gr.File(label=\"Upload Loan (Optional)\")\n",
        "            query_input = gr.Textbox(\n",
        "                label=\"Regulatory Question\",\n",
        "                value=\"What are the appraisal requirements?\",\n",
        "                lines=2\n",
        "            )\n",
        "            btn = gr.Button(\"Analyze\", variant=\"primary\")\n",
        "\n",
        "        with gr.Column():\n",
        "            json_output = gr.JSON(label=\"Extracted Data\")\n",
        "            answer_output = gr.Textbox(\n",
        "                label=\"Regulatory Analysis\",\n",
        "                lines=8,\n",
        "                show_copy_button=True\n",
        "            )\n",
        "            context_output = gr.TextArea(\n",
        "                label=\"üîç Verification: Source Context\",\n",
        "                lines=10,\n",
        "                interactive=False\n",
        "            )\n",
        "\n",
        "    # Note: process_pipeline is now async, which Gradio handles natively\n",
        "    btn.click(\n",
        "        process_pipeline,\n",
        "        inputs=[file_input, query_input],\n",
        "        outputs=[json_output, answer_output, context_output]\n",
        "    )\n",
        "\n",
        "print(\"üöÄ Launching Loan Validator...\")\n",
        "demo.launch(debug=True, share=True)"
      ],
      "metadata": {
        "id": "ju6ZeyPqWlSh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 785
        },
        "outputId": "4ec77ec2-78d0-442c-d088-946b56ea2b76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Launching Loan Validator...\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://9f59499b20dc74dead.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://9f59499b20dc74dead.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No file uploaded. Skipping OCR.\n",
            "Retrieving context...\n",
            "No file uploaded. Skipping OCR.\n",
            "Retrieving context...\n",
            "No file uploaded. Skipping OCR.\n",
            "Retrieving context...\n",
            "Processing file: /tmp/gradio/05d27fb82ea73fc995620986cc020cff3ff942a126999b0c2e0545538745a90a/WhatsApp Image 2026-01-07 at 12.19.40 PM 1.jpeg\n",
            "Structuring data (LLM)...\n",
            "Retrieving context...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ‚úÖ Summary\n",
        "This notebook demonstrates how prompt engineering and semantic retrieval\n",
        "can be used to safely apply large language models in a regulated banking\n",
        "environment while maintaining accuracy, transparency, and audit readiness."
      ],
      "metadata": {
        "id": "fc3q2V5NGz7b"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}